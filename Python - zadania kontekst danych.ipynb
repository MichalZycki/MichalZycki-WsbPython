{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87d76c8b",
   "metadata": {},
   "source": [
    "### Opis danych we wszystkich plikach\n",
    "- 'age', - wiek klienta\n",
    "- 'account_name', - imie klienta\n",
    "- 'account_surname', - nazwisko klienta\n",
    "- 'product', - produkt\n",
    "- 'order_city', - miasto z ktorego zlozono zamowienie\n",
    "- 'color', - kolor produktu\n",
    "- 'date', - data produkcji\n",
    "- 'delivery_date', - data dostarczenia\n",
    "- 'production_date', - data zamowienia\n",
    "- 'discount', - upust %\n",
    "- 'ordered', - ilosc zamowiona\n",
    "- 'quantity', - ilosc dostarczona \n",
    "- 'Invoice_Id', - numer faktury, klucz\n",
    "- 'region', - region\n",
    "- 'additional_delivery_cost', - oznaczenie typu dostawy i kosztu dostawy\n",
    "- 'wrh_city', - relacja magazyn z ktorego wyslano towar i destynacja zamowienia\n",
    "- 'price' - cena\n",
    "- 'City' - miasto\n",
    "- 'Zone' - region\n",
    "\n",
    "---\n",
    "'additional_delivery_cost'\n",
    "- T - truck - koszt na sztuke dostarczona (0.15 per sztuka)\n",
    "- C - container - koszt na sztuke zadeklarowana/zamowiona (0.11 per sztuka)\n",
    "- F - flight - koszt na sztuke dostarczona (0.82 per sztuka)\n",
    "- ? - brak danych\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e649b2",
   "metadata": {},
   "source": [
    "**1. Zaimportuj potrzebne biblioteki**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a1d185",
   "metadata": {},
   "source": [
    "**2. Zaimportuj dane**\n",
    "\n",
    "Zaimportuj dane z plikow:\n",
    "- ZadaniaDf1 - csv\n",
    "- ZadaniaDf2.parquet - parquet\n",
    "- ZadaniaDf3 - txt\n",
    "- ZadaniaDf4 - xlsx\n",
    "\n",
    "Nazwy DataFrameow powinny miec odpowiednio nazwy df1,df2,df3,df4\n",
    "Dane powinny być zaimportowane w taki sposób aby kolumny posiadaly odpowiednie nazwy oraz unikalny indeks na poczatku"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80a51b0",
   "metadata": {},
   "source": [
    "**3. Dokonaj rewizji danych**\n",
    "\n",
    "Dokonaj wstępnej rewizji każdego DataFrameu:\n",
    "- Przejrzyj kilka pierwszych i ostatnich rekordow kazdego zestawu danych\n",
    "- Zweryfikuj czy w danych pojawiaja sie nulle oraz ile ich jest (Zwroc uwage na dane z formatu parquet)\n",
    "- Zidentyfikuj ewentualne klucze w celu polaczenia zestawow\n",
    "- Zidentyfikuj czy dane sie duplikuja (kolumny)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77a9537",
   "metadata": {},
   "source": [
    "**4. Nadpisz datasety**\n",
    "- Nadpisz wszystkie datasety tak aby posiadaly wylacznie unikalne kolumny (brak duplikatow - nalezy wybrac kolumny albo zastosowac drop). \n",
    "- Pamietaj aby nie usunac kolumn ktore sa zidentyfikowane jako klucze. \n",
    "- Nadaj prefix \"u_\" dla kazdego datasetu. Nawet jesli dataset nie jest redukowany powinien otrzymac prefix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5457d6e5",
   "metadata": {},
   "source": [
    "**5. Polacz datasety**\n",
    "- Polacz ze soba datasety. \n",
    "- Dolaczaj do siebie datasety df1 do df2 etc. Kazde kolejne polaczenie nadpisuje pod nazwa \"u_df1_merge\". \n",
    "- Po skonczonych polaczeniach usun niepotrzebna kolumne \"City\" i zapisz dataset jako \"merged_df\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e541e3",
   "metadata": {},
   "source": [
    "**6. Zapisz dane do pliku, wykonaj ponowna analize danych i pogleb ja**\n",
    "- Zapisz dane do pliku .csv pod nazwa \"merged_df\". \n",
    "- Zrestartuj kernel aby zwolnic pamiec ram. \n",
    "- Odczytaj zapisany wczesniej plik i dokonaj jego analizy, sprawdz czy wczesniej ustalone kolumny z pustymi wartosciami sa takie same czy cos sie zmienilo\n",
    "- Wstepna wizualizacja danych przy tak duzej ilosci danych moze byc nieskuteczna/nieczytelna. Dlatego poleca sie zweryfikowac unikalne wartosci dla kazdej z kolumn. W przypadku ograniczenia widocznosci poleca sie przekonwertowac dane na liste.\n",
    "- Mozna pominac klucz po ktorym laczono dane poniewaz jest unikalny "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ada6e99",
   "metadata": {},
   "source": [
    "**7. Wyczysc dane I - usuwanie**\n",
    "Po konsultacji z odbiorcami danych ustalono:\n",
    "- \"product\" - nalezy usunac wszystkie rekordy ktore w kolumnie posiadaja puste wartosci, bez tego analiza sprzedazy bedzie skrzywiona\n",
    "- \"quantity\" - nalezy usunac wszystkie rekordy ktore w kolumnie posiadaja ujemne wartosci, bez tego analiza sprzedazy bedzie skrzywiona, dane obarczone bledami\n",
    "- \"region\" - nalezy usunac kolumne gdyz jest pusta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4503c52",
   "metadata": {},
   "source": [
    "**8. Wyczysc dane II - zastepowanie pustych**\n",
    "Po konsultacji z odbiorcami danych ustalono ze puste w:\n",
    "- \"account_name\" - uzupelniamy \"John\"\n",
    "- \"account_surname\" - uzupelniamy \"Doe\"\n",
    "- \"order_city\" - uzupelniamy najczestszym wystapieniem w kolumnie dla niepustych\n",
    "- \"discount\" - uzupelniamy \"0.0\"\n",
    "- \"Zone\" - kasujemy kolumne \"zone\",mergujemy ponownie data set z df4, nowa kolumna Zone powinna byc juz uzupelniona po wypelnieniu \"order_city\", kasujemy kolune \"City\", dataset nadpisujemy z ta sama nazwa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1321b57b",
   "metadata": {},
   "source": [
    "**9. Wyczysc dane III - podmiana danych, zmiana typow**\n",
    "Po konsultacji z odbiorcami danych ustalono ze zamieniamy dane:\n",
    "- \"age\" - dane powyzej 100 lat sa poprawne ale pomnozone przez 10, nalezy je podzielic przez 10\n",
    "- \"account_name\" - nalezy zkapitalizowac\n",
    "- \"account_surname\" - nalezy usunac prefixy \"Old_\"\n",
    "- \"color\" - nalezy zkapitalizowac\n",
    "- \"production_date\" - kolumne nalezy przekonwertowac na datetime \"RRRR-MM-DD\"\n",
    "- \"date\" - kolumne nalezy przekonwertowac na datetime \"RRRR-MM-DD\"\n",
    "- \"delivery_date\" - kolumne nalezy przekonwertowac na datetime \"RRRR-MM-DD\"\n",
    "- \"wrh_city\" - zostawiamy tylko pierwszy czlon przed \"_\" - wrh\n",
    "- \"discount\" - kolumne nalezy przekonwertowac na float\n",
    "\n",
    "Wszystkie zmiany wykonujemy funkcjami z pozimu serii/kolumny za wyjatkiem konwertowania kolumn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962ffb62",
   "metadata": {},
   "source": [
    "**10. Dodawanie kolumn**\n",
    "Po konsultacji z odbiorcami danych ustalono zamieniamy dane:\n",
    "- \"cost\" - tworzymy kolumne wartoscia kosztow na podstawie opisu kolumny 'additional_delivery_cost' np. jezeli w kolumnie mamy TC to mnozymy wartosc quantity x 0.15(T) i dodajemy ordered x 0.11(C), w przypadku \"?\" stosujemy wartosc ((0.15+0.11+0.82)/3) x quantity. Dodatkowo kazdego wyniku dodajemy koszty pozostale na poziomie 1.5(nie mnozymy przez ilosci, jednorazowa kwota)\n",
    "- \"revenue\" - tworzymy kolumne ktora jest wynikiem quantity x (price-(price x discount))\n",
    "- \"margin\" - revenue - cost\n",
    "- \"order_time\" - delivery_time - production_date\n",
    "- \"lost_revenue\" - tworzymy kolumne ktora jest wynikiem (ordered - quantity) x (price-(price x discount))\n",
    "- \"year\" - kolumna z rokiem na podstawie konwersji production_date\n",
    "\n",
    "Wszystkie zmiany wykonujemy funkcjami z poziomu DataFrameu za wyjatkiem konwersji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82696ae",
   "metadata": {},
   "source": [
    "**11. Redukcja danych zbednych danych i wizualna korekcja**\n",
    "Po konsultacji z odbiorcami danych ustalono:\n",
    "- kasujemy:\n",
    "    - account_name\n",
    "    - account_surname\n",
    "    - Invoice_Id\n",
    "    - date\n",
    "    - delivery_date\n",
    "    - discount\n",
    "    - ordered\n",
    "    - quantity\n",
    "    - additional_delivery_cost\n",
    "    - price\n",
    "- zmieniamy nazwy kolumn:\n",
    "    - \"age\":\"Wiek\",\n",
    "    - \"product\":\"Produkt\",\n",
    "    - \"order_city\":\"Miasto_zamowienia\",\n",
    "    - \"color\":\"Kolor\",\n",
    "    - \"production_date\":\"Data_zamowienia\",\n",
    "    - \"wrh_city\":\"Magazyn\",\n",
    "    - \"Zone\":\"Region\",\n",
    "    - \"revenue\":\"Przychow\",\n",
    "    - \"cost\":\"Koszt\"\n",
    "    - \"margin\":\"Marza\",\n",
    "    - \"order_time\":\"Czas_dostawy\",\n",
    "    - \"lost_revenue\":\"Utracony_przychow\"\n",
    "\n",
    "Wszystkie zmiany wykonujemy funkcjami z poziomu DataFrameu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba499ee",
   "metadata": {},
   "source": [
    "**12. Wizualizacje pogladowe**\n",
    "W trakcie przetwarzania danych dzial sprzedazy poprosil Ciebie o pokazanie 3 szybkich widokow danych\n",
    " - wykresu slupkowego (pionowego) na ktorym znajduja sie sumy Przychodu i Utraconego przychodu dla wszystkich lat, wykres powinien posiadac siatke (aby wykonac wykres nalezy zgrupowac Przychod i Utracony przychod po Roku, zsumowac a nastepnie wygenerowac wykres)\n",
    " - wykresu slupkowego (pionowego) na ktorym znajduje sie sumy Przychodu dla top 5 produktow (aby wykonac wykres nalezy zgrupowac Przychod po Produkcie, zsumowac, wylistowac top 5, a nastepnie wygenerowac wykres)\n",
    " - wykresu slupkowego (poziomego) na ktorym znajduja sie sumych Przychodu dla Wieku i Produktu dla top 5 zgrupowan tych elementow (aby wykonac wykres nalezy zgrupowac Przychod po Wieku i Produkcie, zsumowac, wylistowac top 5 a nastepnie wygenerowac wykres)\n",
    "\n",
    "Wszystkie wykresy sa pogladowe, wiec nie ma koniecznosci zmiany ich oprawy wizualnej"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
